{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Speech Emotion Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWdOIs1jnY3b",
        "colab_type": "text"
      },
      "source": [
        "Download dataset and unzip it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkESiMRPjyWD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "\n",
        "fileid='1FUZJECbq2GSXnzoBXpptz0-3IapCXUKx'\n",
        "filename='emotion.zip'\n",
        "\n",
        "#https://drive.google.com/open?id=1FUZJECbq2GSXnzoBXpptz0-3IapCXUKx\n",
        "\n",
        "! wget --save-cookies cookies.txt 'https://docs.google.com/uc?export=download&id={fileid}' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1/p' > confirm.txt\n",
        "\n",
        "! wget --load-cookies cookies.txt -O {filename} 'https://docs.google.com/uc?export=download&id='{fileid}'&confirm='$(<confirm.txt)\n",
        "\n",
        "! unzip -q -n emotion.zip\n",
        "\n",
        "# pip install librosa"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TmTJI8utl7t9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xV2e4QGl-E9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import librosa\n",
        "from fastai.vision import *\n",
        "from IPython.display import Audio\n",
        "import librosa.display\n",
        "\n",
        "import re\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.models import Model, load_model\n",
        "\n",
        "from keras.layers import Input, Dense, Embedding, Conv2D, MaxPool2D, Lambda, LSTM, TimeDistributed, Masking, Bidirectional\n",
        "from keras import losses, optimizers\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "548w4c8aj3Lp",
        "colab_type": "text"
      },
      "source": [
        "Function to extract features from sound"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_8457hOjZky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_extractor3(folder_name):\n",
        "    df = pd.DataFrame(columns=['feature', 'label'])\n",
        "    audio_files_dir = Path('meld')/folder_name\n",
        "    bookmark=0\n",
        "    duration = 12\n",
        "    for label in ['neutral','happy','disgust','sad','fear']:\n",
        "        label_str = label\n",
        "        audio_files = list(Path(audio_files_dir/label).glob('*.wav'))\n",
        "        print(label_str)\n",
        "\n",
        "        for audio_file in audio_files:\n",
        "            samples, sr = librosa.load(audio_file, res_type='kaiser_fast',duration=duration,sr=16000*2)\n",
        "            # print(samples.shape, sample_rate)\n",
        "            samples = np.concatenate([samples, np.zeros(duration*sr-samples.shape[0])])\n",
        "            # print(samples.shape)\n",
        "\n",
        "            mfcc = librosa.feature.mfcc(y=samples, sr=sr, n_mfcc=50, hop_length=256)\n",
        "            \n",
        "            \n",
        "            \n",
        "            # print(mfcc.shape)\n",
        "            # print(spectral_center.shape)\n",
        "            # print(chroma.shape)\n",
        "            # print(spectral_contrast.shape)\n",
        "            # print(spectral_bandwidth.shape)\n",
        "            # print(flatness.shape)\n",
        "            # print(zero_crossing.shape)\n",
        "            # print(fourier_tempogram.shape, \"\\n---\\n\")\n",
        "            \n",
        "            # data = np.concatenate([mfcc, spectral_center, chroma, spectral_contrast, spectral_bandwidth, flatness, zero_crossing], axis = 0)\n",
        "            data = np.concatenate([mfcc], axis = 0)\n",
        "\n",
        "            df.loc[bookmark] = [data, label_str]\n",
        "            bookmark=bookmark+1\n",
        "\n",
        "    return df\n",
        "\n",
        "#Generating the features for train and val\n",
        "\n",
        "# df = feature_extractor3('train')\n",
        "# df.to_pickle('drive/My Drive/data/features_4_train.csv')\n",
        "# df = feature_extractor3('val')\n",
        "# df.to_pickle('drive/My Drive/data/features_4_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTtAWselkVwM",
        "colab_type": "text"
      },
      "source": [
        "Function to get one hot encoded vector according to label int"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gl4mtGfkSDl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_one_hot(label,num_classes=5):\n",
        "    label_arr = [0]*num_classes\n",
        "    label_arr[label]=1\n",
        "    return label_arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoeVcqv7m0SH",
        "colab_type": "text"
      },
      "source": [
        "Function to get a dictionary having dialogueId_utteranceId as the key"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m551OGDcmmEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def feature_df_convertor(folder_name, df):\n",
        "    # df = pd.DataFrame(columns=['feature', 'label'])\n",
        "    audio_files_dir = Path('meld')/folder_name\n",
        "    bookmark=0\n",
        "\n",
        "    index_list = []\n",
        "    for label in ['neutral','happy','disgust','sad','fear']:\n",
        "        label_str = label\n",
        "        audio_files = list(Path(audio_files_dir/label).glob('*.wav'))\n",
        "        # print(label_str)\n",
        "\n",
        "        for audio_file in audio_files:\n",
        "            audio_file_name = audio_file.as_posix().split(\"/\")[3]\n",
        "            x = re.findall(\"\\d+\", audio_file_name)\n",
        "            feature_id = x[0]+\"_\"+x[1]\n",
        "            index_list.append(feature_id)\n",
        "    \n",
        "    df.index = index_list\n",
        "    return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koKD87zTkmO4",
        "colab_type": "text"
      },
      "source": [
        "Function to get a dictionary having dialogues, utterances ids as keys and features as outputs. Also, returns the maximum number of utterances in the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5c3LTyCkeOl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_max_utts(folder_name):\n",
        "    audio_files_dir = Path('meld')/folder_name\n",
        "\n",
        "    index_list = {}\n",
        "    max_l=0\n",
        "    for label in ['neutral','happy','disgust','sad','fear']:\n",
        "        label_str = label\n",
        "        audio_files = list(Path(audio_files_dir/label).glob('*.wav'))\n",
        "        # print(label_str)\n",
        "\n",
        "        for audio_file in audio_files:\n",
        "            audio_file_name = audio_file.as_posix().split(\"/\")[3]\n",
        "            x = re.findall(\"\\d+\", audio_file_name)\n",
        "\n",
        "            key = (int)(x[0])\n",
        "            x[1] = (int)(x[1])\n",
        "            try:\n",
        "                index_list[key].append(x[1])\n",
        "            except:\n",
        "                index_list[key] = [x[1]]\n",
        "            \n",
        "            max_l = max(max_l, len(index_list[key]))\n",
        "    \n",
        "    return index_list, max_l\n",
        "\n",
        "index_list, max_utts = get_max_utts('train')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpe9OsOFk_cW",
        "colab_type": "text"
      },
      "source": [
        "Function to return an array of embeddings of the sound arranged according to dialogues_utterances. \n",
        "\n",
        "Also, returns the no. of utterances in it, labels of the data and a weight matrix which would be passed to the neural network which would tell which utterances should be considered while training/testing it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99tcZvcsk6pv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_embeddings(df_utt,dialogue_list):\n",
        "    embedding_size = np.mean(df_utt.iloc[0].feature, axis=0).shape\n",
        "    embeddings = []\n",
        "    lengths = []\n",
        "    labels = []\n",
        "    weights = []\n",
        "\n",
        "    for dialogue in dialogue_list.keys():\n",
        "        dialogue_embeddings = []\n",
        "        dialogue_labels = []\n",
        "        weights_local = np.zeros((max_utts))\n",
        "\n",
        "        dialogue_list[dialogue].sort()\n",
        "        for utt_id in dialogue_list[dialogue]:\n",
        "            d = str(dialogue)\n",
        "            ui = str(utt_id)\n",
        "            dialogue_embeddings.append(np.mean(df_utt.loc[d+'_'+ui].feature[:30,:], axis=0).T)\n",
        "            dialogue_labels.append(get_one_hot(df_utt.loc[d+'_'+ui].label2))\n",
        "        \n",
        "        weights_local[:len(dialogue_list[dialogue])] = 1.0\n",
        "        ##Do something about missings utterances\n",
        "\n",
        "        for k in range(max_utts-len(dialogue_embeddings)):\n",
        "            dialogue_embeddings.append(np.zeros(embedding_size).T)\n",
        "            dialogue_labels.append(get_one_hot(3))\n",
        "        # print(dialogue_embeddings)\n",
        "        embeddings.append(dialogue_embeddings)\n",
        "        lengths.append(len(dialogue_embeddings))\n",
        "        labels.append(dialogue_labels)\n",
        "        weights.append(weights_local)\n",
        "\n",
        "    return np.array(embeddings), lengths, np.array(labels), np.array(weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agiaJbR_lp3B",
        "colab_type": "text"
      },
      "source": [
        "A pipeline function which runs the above functions in the required order"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PA43jX02liRb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pipeline(folder_name, input_df):\n",
        "    df = feature_df_convertor(folder_name, input_df)\n",
        "    \n",
        "    df.sort_index(inplace=True)\n",
        "    label_df = pd.DataFrame(df['label'])\n",
        "    label_df['label'] = pd.Categorical(label_df['label'])\n",
        "    df['label2'] = label_df['label'].cat.codes\n",
        "    print(dict( enumerate(label_df['label'].cat.categories ) ))\n",
        "\n",
        "    id_list, max_utts = get_max_utts(folder_name)\n",
        "\n",
        "    embeddings, lengths, labels, weights = get_embeddings(df, id_list)\n",
        "    return embeddings, lengths, labels, weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmmxvgJRmC4N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "372d53ea-8284-4910-f837-39e9c3ac8568"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsMNjkTpmOpa",
        "colab_type": "text"
      },
      "source": [
        "Reading the features, after running the function for extraction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8u9KG4WYlpLV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_pickle('drive/My Drive/data/features_5_train.csv')\n",
        "df_test = pd.read_pickle('drive/My Drive/data/features_5_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEo1Ke39mEVz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "bdf476e1-bfab-47a9-959a-855afbd4dc4d"
      },
      "source": [
        "embeddings_train, lengths_train, labels_train, weights_train  = pipeline('train', df_train)\n",
        "embeddings_train.shape, len(lengths_train), labels_train.shape, weights_train.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'disgust', 1: 'fear', 2: 'happy', 3: 'neutral', 4: 'sad'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((931, 21, 1251), 931, (931, 21, 5), (931, 21))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5VkkTLjyme5A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "8562352f-5168-44bf-ddbf-acb52c01f4fa"
      },
      "source": [
        "embeddings_val, lengths_val, labels_val, weights_val = pipeline('val', df_test)\n",
        "embeddings_val.shape, len(lengths_val), labels_val.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'disgust', 1: 'fear', 2: 'happy', 3: 'neutral', 4: 'sad'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((93, 21, 1251), 93, (93, 21, 5))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yggvy1KpJEa",
        "colab_type": "text"
      },
      "source": [
        "Here, we can see that the data is heavily imbalanced. We'll be training using weighted loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOYN2gcBnzZK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "767668fb-528f-44aa-a931-b262c793ecfe"
      },
      "source": [
        "df_train['label'].value_counts()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "neutral    4592\n",
              "happy      1609\n",
              "sad         705\n",
              "disgust     232\n",
              "fear        216\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZKZi_fipIQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def weighted_categorical_crossentropy(weights):\n",
        "    weights = K.variable(weights)\n",
        "        \n",
        "    def loss(y_true, y_pred):\n",
        "        # scale predictions so that the class probas of each sample sum to 1\n",
        "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
        "        # clip to prevent NaN's and Inf's\n",
        "        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
        "        # calc\n",
        "        loss = y_true * K.log(y_pred) * weights\n",
        "        loss = -K.sum(loss, -1)\n",
        "        return loss\n",
        "    \n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-rN2kK7rBPS",
        "colab_type": "text"
      },
      "source": [
        "Loading a model which was trained in experiments\n",
        "\n",
        "The model is trained on a sequence of Bidirectional LSTMs. LSTMs seemed a good fit because they usually work very well when given the context (*which in this case were the past and future utterances in the dialogue*). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tUwIWh1CpStH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = [14.79310344827586,15.25925925925926,2.853946550652579,1.1,6.513475177304964]\n",
        "weights_2 = [0.38493166911477*5, 0.41344512608623446*5, 0.055502888275094246*5, 0.019447767254927403*5, 0.12667254926897395*5]\n",
        "\n",
        "loss = weighted_categorical_crossentropy(weights)\n",
        "\n",
        "adadelta = optimizers.Adadelta(decay = 0.1)\n",
        "\n",
        "model = load_model('drive/My Drive/data/models_ker/weights_try_2.hdf5',\n",
        "                        custom_objects={'loss': loss})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0kEiKdzrdT0",
        "colab_type": "text"
      },
      "source": [
        "Code to train the neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYaCxyq4pwQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "epochs = 100\n",
        "batch_size = 64\n",
        "\n",
        "checkpoint = ModelCheckpoint('drive/My Drive/data/models_ker/weights_try_5.hdf5', monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
        "history = model.fit(embeddings_train, labels_train,\n",
        "                epochs=epochs,\n",
        "                batch_size=batch_size,\n",
        "                sample_weight = weights_train,\n",
        "                shuffle=True, \n",
        "                callbacks=[checkpoint],\n",
        "                validation_data=(embeddings_val, labels_val, weights_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SGXUbLctifY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "124f1878-d872-45f5-fd20-54d95dc0a8d2"
      },
      "source": [
        "gc.collect()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "899"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ic7hEE_0rQeI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "74f44d18-fe6d-4feb-b203-8f5e40e83227"
      },
      "source": [
        "confusion_matrix(np.argmax(labels_val, axis=2).flatten(), np.argmax(model.predict(embeddings_val), axis=2).flatten())"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  14,    0,    0,   11,    3],\n",
              "       [  11,    3,    0,   10,    1],\n",
              "       [  89,    2,   10,   77,    3],\n",
              "       [1344,    7,   14,  260,   15],\n",
              "       [  33,    0,    2,   40,    4]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nx6HUD1Urr-Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "417dfcfa-d449-4143-e9cb-f23a4e722a6d"
      },
      "source": [
        "true_label = np.argmax(labels_val, axis=2).flatten()\n",
        "predicted_label = np.argmax(model.predict(embeddings_val), axis=2).flatten()\n",
        "print('Weighted F-Score: ', precision_recall_fscore_support(true_label, predicted_label, average='weighted'))"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Weighted F-Score:  (0.5347761750039339, 0.2263184843830005, 0.31235768336112757, None)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93XcBUhT0sK_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5d182813-68b1-4e23-82ee-3b4fa47269f5"
      },
      "source": [
        "val_acc = accuracy_score(true_label, predicted_label)\n",
        "val_acc"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2263184843830005"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RKlsx0B5y4ci",
        "colab_type": "text"
      },
      "source": [
        "However, this model wasn't able to converge well, maybe because of the imbalance of data, or maybe because of bad features. So, I tried running it on some standard sklearn classifiers, which gave better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nodzu5lj2duz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_pickle('drive/My Drive/data/features_5_train.csv')\n",
        "df_test = pd.read_pickle('drive/My Drive/data/features_5_test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gROR5ia0sI91",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.array(df_train.feature.values.tolist())\n",
        "x_train = np.mean(x_train, axis=1)\n",
        "y_train = np.array(df_train.label.tolist())\n",
        "\n",
        "x_test = np.array(df_test.feature.values.tolist())\n",
        "x_test = np.mean(x_test, axis=1)\n",
        "y_test = np.array(df_test.label.tolist())\n",
        "\n",
        "scaler = StandardScaler().fit(x_train)\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blskmLgczeGB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "bd193ff6-93a8-461c-d80a-0a0116e3770f"
      },
      "source": [
        "clf = OneVsRestClassifier(KNeighborsClassifier(n_neighbors=7))\n",
        "\n",
        "clf.fit(x_train, y_train)\n",
        "\n",
        "y_pred=clf.predict(x_train)\n",
        "print(\"Train accuracy    :\",accuracy_score(y_true=y_train, y_pred=y_pred))\n",
        "\n",
        "y_pred=clf.predict(x_test)\n",
        "print(\"Validation accuracy: \",accuracy_score(y_true=y_test, y_pred=y_pred))\n",
        "print('Weighted FScore: ', precision_recall_fscore_support(y_test, y_pred, average='weighted'))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train accuracy    : 0.6418275768289367\n",
            "Validation accuracy:  0.6060240963855422\n",
            "Weighted FScore:  (0.4797828748147671, 0.6060240963855422, 0.5129072559047266, None)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZr2EVeF3_Kh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}